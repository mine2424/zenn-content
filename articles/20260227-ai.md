---
title: "AIエージェントの「計画力」を上げる — ReActパターンの本質と設計思想"
emoji: "🧠"
type: "tech"
topics: ["ai", "llm", "aiagent", "promptengineering"]
published: false
---

## 「とりあえず聞く」から「考えてから動く」へ

LLMを使ったシステムを作るとき、最初は「質問を投げて答えをもらう」という形から始まります。しかしこれだけでは、複雑なタスクをこなすには不十分です。

例えば「競合他社の最新情報をまとめてレポートを作って」というタスクを考えると、LLMに一発で投げても良い結果は得られません。情報を検索し、それを読み込み、整理し、文章にまとめる——という複数のステップが必要だからです。

これを解決するのがAIエージェントの設計思想であり、その核心にあるのが**ReActパターン**です。

## ReActとは何か

ReActとは「**Re**asoning + **Act**ing」の略で、LLMに「考える（Reasoning）」と「行動する（Acting）」を交互に繰り返させるパターンです。

具体的には以下のループを回します：

1. **Thought（思考）**: 今何をすべきか、なぜそれが必要かを考える
2. **Action（行動）**: ツール（検索・計算・API呼び出しなど）を使って情報を取得する
3. **Observation（観察）**: 行動の結果を観察する
4. **（繰り返し）**: 観察結果をもとに次の思考へ

このループを必要な回数だけ繰り返し、十分な情報が揃ったら最終的な答えを出します。

なぜこれが有効なのか。人間が複雑なタスクをこなすときも同じように「考えて→動いて→確認して→また考える」というプロセスを踏んでいます。ReActはその人間の思考プロセスをLLMに模倣させる設計です。

## Chain-of-Thoughtとの違い

ReActと混同されやすいのがChain-of-Thought（CoT）です。CoTも「ステップバイステップで考えさせる」手法ですが、根本的な違いがあります。

**CoT**はLLMの内部推論だけを引き出します。外部ツールを使わず、モデルが持つ知識だけで段階的に答えに辿り着く。だから「モデルが知らないこと」には対応できません。

**ReAct**は推論と外部情報取得を組み合わせます。「今の知識では足りない」と判断したらWebを検索し、計算が必要なら計算ツールを叩き、データベースから情報を引いてくる。リアルタイムの情報や専門的な計算が必要なタスクに対応できます。

この違いは「頭の中だけで考える」vs「メモを取りながら調べて考える」というアナロジーで理解できます。

## ツール設計が命運を分ける

ReActパターンの実装で最も重要なのは、実はLLMの選択でもプロンプトの工夫でもなく、**ツール設計**です。

ツールとは、LLMが呼び出せる機能の単位です。Web検索、計算、ファイル読み書き、APIコールなど。このツールの設計が悪いと、LLMがどれだけ賢くても良い結果は得られません。

良いツール設計の原則は3つあります。

**原則1: 単一責任**
一つのツールは一つのことだけをする。「検索してサマリーして保存する」という複合ツールより、「検索する」「サマリーする」「保存する」を別々のツールにする方が、LLMが使いやすく、デバッグもしやすい。

**原則2: 明確なdescription**
LLMはdescriptionを読んでどのツールを使うか判断します。曖昧なdescriptionは誤用の原因になります。「何をするツールか」「どんな入力を期待するか」「どんな状況で使うべきか」を明確に記述することが重要です。

**原則3: 失敗を設計する**
ツールは必ず失敗します。ネットワークエラー、APIの制限、予期しない入力。失敗したときにLLMに何を返すかを設計することが、安定したエージェントの条件です。単に例外を投げるのではなく、「何が失敗したか」「どう対処すればよいか」をLLMが理解できる形で返すことが重要です。

## 「計画」と「実行」を分離する

ReActパターンをさらに発展させた考え方として、計画フェーズと実行フェーズを明示的に分ける設計があります。

まずLLMに「このタスクを達成するために何をすべきか、ステップに分解して」と考えさせます。その計画を確認した上で実行に移る。これにより、途中で方向性がずれてしまうリスクが減ります。

特に長いタスクや、途中でユーザーの承認が必要なタスクでは、この計画・実行の分離が重要になります。

## エラーからの回復設計

ReActパターンで避けて通れないのが「ループ地獄」です。ツールが失敗し続け、LLMが同じ行動を繰り返し、いつまでも終わらない——これは実装を始めた多くの人がはまる問題です。

対策として重要なのは：
- **最大ステップ数の設定**: 何回ループしたら強制終了するかを決める
- **エラー履歴の参照**: 「このツールはすでに失敗している」という情報をLLMに渡す
- **代替戦略の提示**: 「Aが失敗したらBを試す」という選択肢をdescriptionに含める

## まとめ：エージェントは「設計力」で決まる

ReActパターンは強力ですが、ツールを作っただけでは機能しません。どんな粒度でツールを分割するか、descriptionをどう書くか、失敗をどう処理するか——この設計力がエージェントの品質を決めます。

LLMの性能向上とともにエージェントの可能性は広がり続けていますが、それを活かすのはエンジニアの設計思想です。「とりあえず繋いでみる」から「設計して動かす」へ。そのシフトがAIエージェント開発の核心です。
