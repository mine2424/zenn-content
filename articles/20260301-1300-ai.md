---
title: "LLMアプリケーションにおけるコンテキスト設計の考え方"
emoji: "🧠"
type: "tech"
topics: ["llm", "ai", "プロンプト", "アーキテクチャ", "chatgpt"]
published: false
---

## はじめに

LLMを使ったアプリケーション開発が一般化してきた昨今、「プロンプトを書く」という行為そのものよりも、**どのような情報をどのタイミングでモデルに渡すか**という「コンテキスト設計」の重要性が増しています。

プロンプトエンジニアリングの話題は多く見かけますが、アプリケーション全体の設計としてコンテキストをどう扱うかは、意外と体系的に語られることが少ないように感じます。この記事では、LLMアプリケーションにおけるコンテキスト設計の考え方を整理してみます。

## コンテキストとは何か

LLMに渡すコンテキストは、大まかに以下の種類に分類できます。

- **システムコンテキスト**：モデルの役割・振る舞いを定義するもの
- **ユーザーコンテキスト**：ユーザー固有の情報（プロフィール、過去の行動など）
- **タスクコンテキスト**：今回のリクエストに直接関係する情報
- **会話コンテキスト**：これまでのやり取りの履歴

それぞれを適切に管理しないと、「モデルが的外れな回答をする」「毎回同じ質問を繰り返す」「トークンを無駄に消費する」といった問題が起きます。

## コンテキストウィンドウという制約

LLMには「コンテキストウィンドウ」と呼ばれる、一度に処理できる情報量の上限があります。この制約があることで、すべての情報を詰め込めばよいというわけにはいきません。

重要なのは、**何を入れるかではなく、何を削るか**です。

たとえばチャットアプリを作るとき、会話履歴をすべてそのまま渡し続けると、やがてウィンドウが溢れます。そこで一般的に取られるアプローチは以下のようなものです。

- **スライディングウィンドウ方式**：直近N件の会話のみを保持する
- **サマリー方式**：古い会話を要約して圧縮する
- **重要度ベースの選択**：意味的な関連性が高いものだけを選んで渡す

どのアプローチが適切かは、アプリケーションの性質によります。カスタマーサポートのように過去のやり取りを参照する必要があるものと、単発の質問応答では、設計が大きく変わります。

## 動的コンテキスト構築という考え方

より高度なアプリケーションでは、リクエストが来るたびに**その場でコンテキストを組み立てる**設計が有効です。

たとえば：

1. ユーザーの入力を受け取る
2. 意味的に近い過去の会話やドキュメントをベクトル検索で取得（RAG）
3. ユーザーの属性情報を取得
4. これらを組み合わせてプロンプトを構築する
5. LLMに渡す

```python
def build_context(user_input: str, user_id: str) -> str:
    relevant_docs = vector_store.search(user_input, top_k=3)
    user_profile = user_store.get(user_id)
    
    context = f"""
あなたは{user_profile.role}向けのアシスタントです。

【参考情報】
{format_docs(relevant_docs)}

【ユーザーの質問】
{user_input}
"""
    return context
```

このアプローチをRAG（Retrieval-Augmented Generation）と呼びますが、ポイントは「全部入れる」のではなく「関連するものだけを動的に選んで入れる」という発想です。

## コンテキストの一貫性を保つ

複数のLLM呼び出しを連鎖させる「エージェント」や「チェーン」型のアプリケーションでは、**コンテキストの一貫性**が課題になります。

ある呼び出しで得た結果を次の呼び出しに渡す際、どの情報を引き継ぎ、どの情報を捨てるかを意識的に設計しなければ、中間の処理で重要な前提が失われてしまいます。

たとえば「複数のウェブページを調査してレポートを作る」エージェントを作るとき：

- 各ページの要約だけを引き継ぐ（生データは捨てる）
- 「まだ調査していない点」を状態として保持する
- 最終的なレポート生成時に必要な情報だけを集約する

こういった**情報の蒸留**を各ステップで行うことが、長いチェーンを安定させるコツです。

## プロンプトとコンテキストを分けて考える

開発現場でよく見る問題として、「プロンプト」と「コンテキスト」を混同してしまうことがあります。

- **プロンプト**：モデルに何をさせるかの指示（比較的固定的）
- **コンテキスト**：モデルが参照すべき情報（動的に変わる）

この2つを明確に分けて管理することで、プロンプトの改善とコンテキスト管理の改善を独立して行えるようになります。プロンプトはコードのように管理し、コンテキストはデータとして扱う、という考え方です。

## コンテキストの品質を測る

コンテキスト設計の改善サイクルを回すには、「どのコンテキストが役に立ったか」を評価する仕組みが必要です。

実際の回答と期待される回答を比較する評価用テストケースを持ち、コンテキストの変更が回答の品質にどう影響するかを継続的に計測する。これはプロンプトの評価と本質的に同じですが、コンテキストに着目することで、より細かい改善ができます。

## おわりに

LLMアプリケーションの品質は、モデルの性能に依存する部分もありますが、コンテキスト設計によって大きく変わります。「どの情報をいつ渡すか」を意識することが、より良いアプリケーションへの近道です。

「とりあえずすべての情報を渡す」から「必要な情報を動的に選んで渡す」へ。この発想の転換が、LLMアプリ開発の一つの重要なステップだと思っています。
