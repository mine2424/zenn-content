---
title: "AIエージェントの「ツール選択」はなぜ難しいのか——設計哲学から考える"
emoji: "🔧"
type: "tech"
topics: ["ai", "llm", "aiagent", "prompt", "設計"]
published: false
---

## はじめに

AIエージェントが急速に普及するにつれ、「ツールをどう定義し、エージェントにどう使わせるか」という問題が設計の中心に据えられるようになってきました。しかし実際にエージェントを構築してみると、ツール選択が想定外に難しいことに気づきます。

単に「ツールの説明文を書く」だけでは、エージェントは正しく選択できません。本記事では、なぜツール選択が難しいのかを構造的に整理し、よりよい設計に向けた考え方を探ります。

---

## ツール選択とは何か

LLMベースのエージェントは、与えられたゴールを達成するために「どのツールを、どの順序で、どんな引数で呼び出すか」を自律的に決定します。このプロセスは人間から見ると魔法のようですが、LLMの内部では単純なテキスト生成として処理されています。

つまりツール選択は、**プロンプトの一部としてLLMに提示されたツール定義を読み、状況に応じた関数呼び出し形式のテキストを生成する**という作業です。この視点に立つと、「なぜ失敗するか」が明確になってきます。

---

## 失敗パターン①：ツールの意図が曖昧

最も多い失敗は、ツールの説明文が「何ができるか」だけを語り、「何をすべき状況か」を語っていないケースです。

たとえば `search_web(query: string)` というツールがあったとして、説明を「ウェブを検索する」とだけ書いてしまうと、LLMはあらゆる情報取得タスクにこのツールを使おうとしてしまいます。社内DBへの問い合わせにも、コードのデバッグにも。

重要なのは **「このツールを使うべき状況」** を明示することです。

```
❌ search_web: ウェブを検索する
✅ search_web: 最新情報や公開されていない事実を調べるときに使う。
   社内データやコードの話には使わないこと。
```

人間が同僚に仕事を依頼するとき、「何ができるか」だけでなく「どんな案件を持ってきてほしいか」まで伝えるのと同じです。

---

## 失敗パターン②：ツールの粒度が揃っていない

ツールが「大きすぎるもの」と「小さすぎるもの」が混在していると、LLMは判断に迷います。

たとえば、

- `generate_full_report()` — レポート全体を生成する巨大なツール
- `format_date(date: string)` — 日付を整形するだけのツール

この2つが同列に並んでいると、エージェントはどの粒度で考えればいいのかがわからなくなります。結果として、巨大なツールに何でも任せてしまったり、逆に細かいツールを何十回も呼び出したりする非効率な動作が生まれます。

ツールの粒度はなるべく揃え、**「1ツール＝1つの責任」** という原則を守ることが重要です。これはソフトウェア設計の単一責任の原則と同じ発想です。

---

## 失敗パターン③：ツール同士の関係性が伝わっていない

実務的なエージェントでは、ツールは単独ではなく連携して使われます。「まずAを実行し、その結果をBに渡す」という依存関係が存在します。

この前提がプロンプトに明示されていないと、LLMはそれぞれのツールを独立したものと捉え、依存関係を無視した呼び出しをしてしまいます。

解決策の一つは、**ツールにメタデータとして「前提条件」や「次に呼ぶべきツール」のヒントを含める**ことです。あるいはシステムプロンプト内に「このエージェントのワークフロー概要」を記述し、ツール同士がどう連携するかの全体像を先に伝えておく方法もあります。

---

## 設計哲学：LLMに「推論しやすい状態」を作る

上記の失敗パターンを見ると、共通するテーマが浮かびます。それは **「LLMが推論しやすい状態を設計者が作る責任がある」** ということです。

LLMは優秀ですが、あいまいな情報から正確な判断を毎回引き出せるわけではありません。特にツール数が多くなればなるほど、コンテキストウィンドウの圧力も高まり、後半のツールほど無視されやすくなります。

このことから、実用的な設計原則として以下が導き出せます。

- **ツール数は最小限に保つ**：10個を超えると精度が落ちやすい
- **説明文は「いつ使うか」を主語にする**：「このツールは〜するときに使う」
- **ツールの名前は動詞+目的語で統一する**：`get_user`, `send_email`, `search_product`
- **用途が似たツールは明示的に区別する**：「〜との違いは〜」と説明文に書く

---

## エージェントの「メタ認知」を育てる

より高度なアプローチとして、エージェント自身にツール選択を振り返らせる設計があります。

具体的には、ツール呼び出しの前後に「なぜこのツールを選んだか」「この選択は適切か」を内部推論させるステップを挟む方法です。いわゆる **Chain-of-Thought（CoT）** や **ReAct** フレームワークの考え方です。

単純にツールを呼び出すのではなく、「Thought → Action → Observation」というループを意識的に設計に組み込むことで、ツール選択の精度は大幅に向上します。

---

## まとめ

AIエージェントのツール選択が難しい理由は、LLMの能力の問題ではなく、多くの場合**ツール定義という設計の問題**です。

- 説明が曖昧 → 誤選択
- 粒度の不統一 → 非効率な呼び出し
- 関係性の未伝達 → 依存関係の無視

これらは適切な設計で解決できます。そしてその設計の本質は「LLMが推論しやすい情報構造を作ること」に集約されます。

エージェント設計はプロンプトエンジニアリングとソフトウェア設計の交差点にあります。両方の視点を持ちながら、ツールを「使わせる」のではなく「使いたくなる状態を作る」という発想で設計に臨むことが、成熟したエージェント開発への第一歩です。
