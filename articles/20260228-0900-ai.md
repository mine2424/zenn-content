---
title: "構造化出力でLLMを「信頼できるコンポーネント」にする考え方"
emoji: "🏗️"
type: "tech"
topics: ["llm", "ai", "プロンプトエンジニアリング", "構造化出力"]
published: false
---

## はじめに

LLMをアプリケーションに組み込む際に、多くの開発者が最初に直面する壁があります。それは「LLMの出力は予測不可能だ」という問題です。自然言語を返してくるLLMをコードの中で扱おうとすると、パースエラーや形式の揺れが頻発し、「結局ルールベースのほうが安定する」と感じた経験がある方も少なくないでしょう。

しかし、**構造化出力（Structured Output）** の考え方を正しく理解すると、LLMはシステムの中で「信頼できるコンポーネント」として機能し始めます。この記事では、構造化出力とは何か、なぜそれが重要なのか、そしてどういう設計思想で活用すべきかを丁寧に解説します。

---

## LLMを「コンポーネント」として見るとはどういうことか

従来のソフトウェア開発では、関数やAPIは決定論的です。同じ入力を与えれば、同じ出力が返ってきます。だからこそ、テストが書けて、型が定義でき、後続の処理を安心して書ける。

LLMはその対極にある存在です。確率的に動作し、出力は毎回微妙に異なり、形式も保証されない。これをそのままコードの中に組み込もうとすると、システム全体が「LLMの気まぐれ」に振り回されることになります。

ここで発想を転換する必要があります。LLMの「賢さ」を活かしながら、出力の**インターフェースだけは確定させる**という設計です。

インプット（プロンプト） → **LLMの推論** → アウトプット（決まった形式） → 後続処理

このように、LLMを「中間処理レイヤー」として位置づけ、入出力のインターフェースをコントロールするのが構造化出力の本質です。

---

## 構造化出力の2つのアプローチ

### 1. プロンプトによる誘導

最もシンプルな方法は、プロンプトの中にJSON形式で返すよう明示的に指示することです。

```
以下の文章を分析し、必ず次のJSON形式で返してください。
{
  "sentiment": "positive" | "negative" | "neutral",
  "confidence": 0.0〜1.0の数値,
  "reason": "理由を1文で"
}

分析対象：「このサービスは使いやすくて助かっています」
```

シンプルで導入コストがゼロですが、LLMが指示を無視してマークダウンのコードブロックで囲んだり、余計な説明を付け加えたりする可能性があります。本番環境では後述のAPIレベルの制御と組み合わせるのが現実的です。

### 2. APIレベルの強制（Function Calling / JSON Mode）

OpenAIのFunction CallingやAnthropicのTool Useのような仕組みは、モデルレベルで出力形式を強制します。開発者がスキーマ（どのフィールドが必要か、型は何か）を定義すると、LLMはそのスキーマに従った出力のみを返すよう制約されます。

これはプロンプト誘導と本質的に異なります。プロンプト誘導が「お願い」なら、APIレベルの強制は「契約」です。スキーマに合致しない出力はそもそも生成されないため、パースエラーを心配する必要がなくなります。

---

## なぜ構造化出力が設計上重要なのか

### 疎結合を実現できる

構造化出力を前提にすると、LLMの処理と後続の処理を疎結合にできます。LLMが何を考えてその結論に至ったかは関係なく、出力スキーマさえ守られていれば後続のロジックは正常に動作します。

これはマイクロサービスのAPIが内部実装を隠蔽するのと同じ発想です。LLMは「賢い内部実装」であり、その外側には明確なインターフェースがある。

### テスタビリティが上がる

出力形式が決まっていれば、期待する構造のモックデータを作成し、後続処理のユニットテストを書くことができます。LLM自体のテストは難しいですが、「LLMが返すであろう構造」を前提としたテストは書けます。

### エラーハンドリングが設計できる

形式が決まっていると、「confidence が0.5未満ならユーザーに確認を求める」「categoryが想定外の値ならフォールバック処理を走らせる」といったビジネスロジックを組み込めます。不定形の文字列では、このような判断分岐は書けません。

---

## 設計するときに意識すること

### スキーマはできるだけシンプルに

構造化出力のスキーマは、LLMにとっての制約でもあります。フィールドが多ければ多いほど、LLMはより多くの情報を同時に生成する必要があり、品質が落ちることがあります。

「このフィールドは本当に必要か？」を問い続け、1つのスキーマで1つの責任を持たせる設計を心がけましょう。欲張って多くの情報を一度に取ろうとするより、複数の小さなスキーマを順番に使うほうが結果的に精度が高くなることが多いです。

### 列挙型（Enum）を積極的に使う

自由記述フィールドよりも、選択肢を限定したEnum型のほうがLLMの迷いを減らせます。「感情を返してください」よりも「positive / negative / neutral / mixed のいずれかを返してください」のほうが、一貫した出力が得られます。

### オプショナルフィールドには注意

必須フィールドと任意フィールドを明確に分け、任意フィールドが欠落した場合の挙動を事前に定義しておきましょう。「nullが返ってきたらデフォルト値を使う」というロジックを最初から設計に含めておくことが重要です。

---

## 構造化出力とプロンプト設計の関係

構造化出力を使うと「プロンプトが短くなる」という誤解があります。実際はむしろ逆で、スキーマを正しく埋めさせるために、プロンプトの中でフィールドの意味や期待する値の粒度を丁寧に説明する必要があります。

「reasonフィールドには、判断の根拠を1〜2文で簡潔に記述してください。個人の感情表現ではなく、テキスト内の具体的な表現を根拠にしてください」

このような説明がないと、LLMはフィールドを機械的に埋めるだけになり、出力の品質が低下します。スキーマは「型定義」であり、プロンプトはそのスキーマを「どう埋めるか」の仕様書です。両者はセットで設計するものです。

---

## まとめ

構造化出力は、LLMをアプリケーションの一部として使う際の基本的なアーキテクチャパターンです。重要なのは、以下の3点です。

- **インターフェースとしてのスキーマ**：LLMの出力形式をコントロールし、後続処理と疎結合にする
- **シンプルなスキーマ設計**：1スキーマ1責任、Enumの積極活用、フィールド数は最小限に
- **スキーマとプロンプトはセット**：型定義だけでなく、各フィールドの意味を丁寧に説明する

LLMは「賢いが気まぐれ」な存在です。構造化出力という境界を設けることで、その賢さを活かしながら、システムとしての信頼性を担保できます。AIをシステムに組み込む際は、ぜひこの視点を設計の出発点にしてみてください。
